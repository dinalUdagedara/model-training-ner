{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resume NER with BERT-BiLSTM-CRF (FYP)\n",
        "\n",
        "This notebook trains a **BERT-BiLSTM-CRF** model for Named Entity Recognition on resumes. Entity types: **NAME**, **EMAIL**, **SKILL**, **OCCUPATION**, **EDUCATION**, **EXPERIENCE**. Data should be prepared with `prepare_data.py` in `resume_ner_pipeline/`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependencies\n",
        "\n",
        "Run once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q torch transformers pytorch-crf seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "_drive_base = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n",
        "DATA_PATH = os.path.join(_drive_base, \"merged_resume_ner.json\")\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(\"JSON not found. Mount Google Drive and place merged_resume_ner.json in My Drive root.\")\n",
        "\n",
        "data = []\n",
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            data.append(json.loads(line))\n",
        "print(f\"Loaded {len(data)} resumes\")\n",
        "\n",
        "LABEL_MAPPING = {\n",
        "    \"Name\": \"NAME\", \"Email Address\": \"EMAIL\", \"Skills\": \"SKILL\", \"Designation\": \"OCCUPATION\",\n",
        "    \"Degree\": \"EDUCATION\", \"College Name\": \"EDUCATION\", \"Graduation Year\": \"EDUCATION\",\n",
        "    \"Companies worked at\": \"EXPERIENCE\", \"Years of Experience\": \"EXPERIENCE\", \"Location\": \"O\", \"UNKNOWN\": \"O\",\n",
        "    \"NAME\": \"NAME\", \"EMAIL\": \"EMAIL\", \"SKILL\": \"SKILL\", \"OCCUPATION\": \"OCCUPATION\", \"EDUCATION\": \"EDUCATION\", \"EXPERIENCE\": \"EXPERIENCE\", \"O\": \"O\",\n",
        "}\n",
        "for item in data:\n",
        "    for ann in item.get(\"annotation\", []):\n",
        "        ann[\"label\"] = [LABEL_MAPPING.get(l, \"O\") for l in ann[\"label\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocessing and train/val/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "\n",
        "def tokenize_with_positions(text):\n",
        "    return [(m.group(), m.start(), m.end()) for m in re.finditer(r\"\\S+\", text)]\n",
        "\n",
        "def create_bio_tags_fixed(tokens, annotations):\n",
        "    \"\"\"Build BIO tags from token positions and annotation spans; no B-O / I-O.\"\"\"\n",
        "    bio = [\"O\"] * len(tokens)\n",
        "    for ann in annotations:\n",
        "        if not ann.get(\"label\") or ann[\"label\"][0] == \"O\":\n",
        "            continue\n",
        "        entity = ann[\"label\"][0]\n",
        "        for pt in ann.get(\"points\", []):\n",
        "            s, e = pt[\"start\"], pt[\"end\"]\n",
        "            first = True\n",
        "            for i, (_, ts, te) in enumerate(tokens):\n",
        "                if te <= s or ts >= e:\n",
        "                    continue\n",
        "                bio[i] = f\"B-{entity}\" if first else f\"I-{entity}\"\n",
        "                first = False\n",
        "    return bio\n",
        "\n",
        "all_sents, all_labels = [], []\n",
        "for item in data:\n",
        "    content = item.get(\"content\", \"\")\n",
        "    anns = item.get(\"annotation\", [])\n",
        "    if not content or not anns:\n",
        "        continue\n",
        "    toks = tokenize_with_positions(content)\n",
        "    if not toks:\n",
        "        continue\n",
        "    labs = create_bio_tags_fixed(toks, anns)\n",
        "    all_sents.append([t[0] for t in toks])\n",
        "    all_labels.append(labs)\n",
        "\n",
        "n = len(all_sents)\n",
        "random.seed(42)\n",
        "idx = list(range(n))\n",
        "random.shuffle(idx)\n",
        "n_train, n_val = int(0.8 * n), int(0.1 * n)\n",
        "train_sents = [all_sents[i] for i in idx[:n_train]]\n",
        "train_labels = [all_labels[i] for i in idx[:n_train]]\n",
        "val_sents = [all_sents[i] for i in idx[n_train : n_train + n_val]]\n",
        "val_labels = [all_labels[i] for i in idx[n_train : n_train + n_val]]\n",
        "test_sents = [all_sents[i] for i in idx[n_train + n_val :]]\n",
        "test_labels = [all_labels[i] for i in idx[n_train + n_val :]]\n",
        "print(f\"Train {len(train_sents)} Val {len(val_sents)} Test {len(test_sents)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. BERT tokenizer and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "TAGS = [\"O\", \"B-NAME\", \"I-NAME\", \"B-EMAIL\", \"I-EMAIL\", \"B-SKILL\", \"I-SKILL\", \"B-OCCUPATION\", \"I-OCCUPATION\", \"B-EXPERIENCE\", \"I-EXPERIENCE\", \"B-EDUCATION\", \"I-EDUCATION\"]\n",
        "LABEL2ID = {t: i for i, t in enumerate(TAGS)}\n",
        "ID2LABEL = {i: t for i, t in enumerate(TAGS)}\n",
        "NUM_LABELS = len(TAGS)\n",
        "\n",
        "def align_to_bert(words, word_labels, tokenizer, max_len=512):\n",
        "    \"\"\"Align word-level labels to BERT subword indices; label only first subword of each word.\"\"\"\n",
        "    first_idx, toks = [], [\"[CLS]\"]\n",
        "    for w in words:\n",
        "        p = tokenizer.tokenize(w) or [tokenizer.unk_token]\n",
        "        first_idx.append(len(toks))\n",
        "        toks.extend(p)\n",
        "    toks.append(\"[SEP]\")\n",
        "    ids = tokenizer.convert_tokens_to_ids(toks)\n",
        "    mask = [1] * len(ids)\n",
        "    aligned = [-100] * len(ids)\n",
        "    for pos, lab in zip(first_idx, word_labels):\n",
        "        if pos < len(aligned):\n",
        "            aligned[pos] = LABEL2ID.get(lab, 0)\n",
        "    if len(ids) > max_len:\n",
        "        ids = ids[: max_len - 1] + [tokenizer.sep_token_id]\n",
        "        mask = mask[: max_len - 1] + [1]\n",
        "        aligned = aligned[: max_len - 1] + [-100]\n",
        "    return ids, mask, aligned\n",
        "\n",
        "class BertNERDataset(Dataset):\n",
        "    \"\"\"Dataset of (input_ids, attention_mask, labels) for BERT NER.\"\"\"\n",
        "    def __init__(self, sents, labels, tokenizer, max_len=512):\n",
        "        self.samples = [align_to_bert(w, l, tokenizer, max_len) for w, l in zip(sents, labels) if len(w) == len(l)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.samples[i]\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "train_ds = BertNERDataset(train_sents, train_labels, tokenizer)\n",
        "val_ds = BertNERDataset(val_sents, val_labels, tokenizer)\n",
        "\n",
        "def collate(batch):\n",
        "    max_l = max(len(b[0]) for b in batch)\n",
        "    pad = 0\n",
        "    return (\n",
        "        torch.tensor([b[0] + [pad] * (max_l - len(b[0])) for b in batch], dtype=torch.long),\n",
        "        torch.tensor([b[1] + [0] * (max_l - len(b[1])) for b in batch], dtype=torch.long),\n",
        "        torch.tensor([b[2] + [-100] * (max_l - len(b[2])) for b in batch], dtype=torch.long),\n",
        "    )\n",
        "\n",
        "rare_tags = {\"B-EDUCATION\", \"I-EDUCATION\", \"B-EXPERIENCE\", \"I-EXPERIENCE\", \"B-OCCUPATION\", \"I-OCCUPATION\"}\n",
        "train_weights = [2.0 if any(t in rare_tags for t in l) else 1.0 for w, l in zip(train_sents, train_labels) if len(w) == len(l)]\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "train_sampler = WeightedRandomSampler(weights=train_weights, num_samples=len(train_weights))\n",
        "train_loader = DataLoader(train_ds, batch_size=8, sampler=train_sampler, collate_fn=collate)\n",
        "val_loader = DataLoader(val_ds, batch_size=8, collate_fn=collate)\n",
        "print(\"Datasets ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model: BERT-BiLSTM-CRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from torchcrf import CRF\n",
        "\n",
        "class BertBiLSTMCRF(nn.Module):\n",
        "    \"\"\"BERT encoder + BiLSTM + CRF for NER.\"\"\"\n",
        "    def __init__(self, bert_name=\"bert-base-uncased\", hidden_dim=256, num_labels=NUM_LABELS, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.bert = BertModel.from_pretrained(bert_name)\n",
        "        self.lstm = nn.LSTM(self.bert.config.hidden_size, hidden_dim // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim, num_labels)\n",
        "        self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
        "        out, _ = self.lstm(self.drop(out))\n",
        "        emissions = self.fc(self.drop(out))\n",
        "        mask_b = attention_mask.bool()\n",
        "        if labels is not None:\n",
        "            labels = labels.clone().masked_fill(labels == -100, 0)\n",
        "            return -self.crf(emissions, labels, mask=mask_b, reduction=\"mean\")\n",
        "        return self.crf.decode(emissions, mask=mask_b)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "model = BertBiLSTMCRF(dropout=0.3).to(device)\n",
        "\n",
        "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "bert_params = list(model.bert.named_parameters())\n",
        "optimizer_grouped = [\n",
        "    {\"params\": [p for n, p in bert_params if not any(nd in n for nd in no_decay)], \"lr\": 2e-5, \"weight_decay\": 0.01},\n",
        "    {\"params\": [p for n, p in bert_params if any(nd in n for nd in no_decay)], \"lr\": 2e-5, \"weight_decay\": 0.0},\n",
        "    {\"params\": [p for n, p in model.named_parameters() if not n.startswith(\"bert.\") and not any(nd in n for nd in no_decay)], \"lr\": 1e-4, \"weight_decay\": 0.01},\n",
        "    {\"params\": [p for n, p in model.named_parameters() if not n.startswith(\"bert.\") and any(nd in n for nd in no_decay)], \"lr\": 1e-4, \"weight_decay\": 0.0},\n",
        "]\n",
        "optimizer = torch.optim.AdamW(optimizer_grouped)\n",
        "print(f\"Model on {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training (with early stopping and validation F1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from seqeval.metrics import f1_score\n",
        "from torch.optim.lr_scheduler import LinearLR, SequentialLR, ConstantLR\n",
        "\n",
        "def run_validation(model, val_loader, device, id2label, num_labels):\n",
        "    \"\"\"Return (val_f1, true_all, pred_all) for early stopping and reporting.\"\"\"\n",
        "    model.eval()\n",
        "    true_all, pred_all = [], []\n",
        "    with torch.no_grad():\n",
        "        for inp, mask, labels in val_loader:\n",
        "            inp, mask = inp.to(device), mask.to(device)\n",
        "            preds = model(inp, mask)\n",
        "            for b in range(inp.size(0)):\n",
        "                m, labs = mask[b].cpu(), labels[b].cpu()\n",
        "                pred_b = preds[b]\n",
        "                tlist, plist = [], []\n",
        "                pos = 0\n",
        "                for i in range(m.size(0)):\n",
        "                    if m[i].item() == 0:\n",
        "                        break\n",
        "                    p = id2label[pred_b[pos]] if pos < len(pred_b) and pred_b[pos] < num_labels else \"O\"\n",
        "                    pos += 1\n",
        "                    if labs[i].item() == -100:\n",
        "                        continue\n",
        "                    tlist.append(id2label[labs[i].item()])\n",
        "                    plist.append(p)\n",
        "                if tlist and plist:\n",
        "                    true_all.append(tlist)\n",
        "                    pred_all.append(plist)\n",
        "    f1 = f1_score(true_all, pred_all, zero_division=0) if true_all else 0.0\n",
        "    return f1, true_all, pred_all\n",
        "\n",
        "EPOCHS = 60\n",
        "PATIENCE = 12\n",
        "best_f1 = 0.0\n",
        "best_state = None\n",
        "epochs_no_improve = 0\n",
        "\n",
        "warmup_epochs = max(1, EPOCHS // 10)\n",
        "scheduler = SequentialLR(optimizer, [\n",
        "    ConstantLR(optimizer, factor=0.1, total_iters=warmup_epochs),\n",
        "    LinearLR(optimizer, start_factor=1.0, end_factor=0.2, total_iters=EPOCHS - warmup_epochs),\n",
        "], milestones=[warmup_epochs])\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for inp, mask, lab in train_loader:\n",
        "        inp, mask, lab = inp.to(device), mask.to(device), lab.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(inp, mask, lab)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        total += loss.item()\n",
        "    scheduler.step()\n",
        "    val_f1, _, _ = run_validation(model, val_loader, device, ID2LABEL, NUM_LABELS)\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} Loss: {total/len(train_loader):.4f} Val F1: {val_f1:.4f} Best: {best_f1:.4f}\")\n",
        "    if epochs_no_improve >= PATIENCE:\n",
        "        print(f\"Early stopping (no improvement for {PATIENCE} epochs).\")\n",
        "        break\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)\n",
        "    print(\"Restored best checkpoint (by val F1).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_DIR = os.environ.get(\"RESUME_NER_SAVE_DIR\", \"resume_ner\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"bert_bilstm_crf_state.pt\"))\n",
        "config = {\"tags\": TAGS, \"bert_name\": \"bert-base-uncased\", \"num_labels\": NUM_LABELS}\n",
        "with open(os.path.join(SAVE_DIR, \"ner_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "print(\"Saved:\", SAVE_DIR)\n",
        "print(\"  - bert_bilstm_crf_state.pt\")\n",
        "print(\"  - ner_config.json\")\n",
        "print(\"  - tokenizer files\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Load saved model and run inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LOAD_DIR = os.environ.get(\"RESUME_NER_LOAD_DIR\", \"resume_ner\")\n",
        "with open(os.path.join(LOAD_DIR, \"ner_config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "    load_config = json.load(f)\n",
        "\n",
        "TAGS = load_config[\"tags\"]\n",
        "LABEL2ID = {t: i for i, t in enumerate(TAGS)}\n",
        "ID2LABEL = {i: t for i, t in enumerate(TAGS)}\n",
        "NUM_LABELS = load_config[\"num_labels\"]\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(LOAD_DIR)\n",
        "model = BertBiLSTMCRF(bert_name=load_config[\"bert_name\"], num_labels=NUM_LABELS).to(device)\n",
        "model.load_state_dict(torch.load(os.path.join(LOAD_DIR, \"bert_bilstm_crf_state.pt\"), map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded from\", LOAD_DIR)\n",
        "\n",
        "def parse_resume(text, tokenizer, model, device, id2label, max_len=512):\n",
        "    \"\"\"Tokenize resume text, run NER, return (words, tags) and entity dict.\"\"\"\n",
        "    words = re.findall(r\"\\S+\", text)\n",
        "    if not words:\n",
        "        return [], [], {}\n",
        "    first_idx, toks = [], [\"[CLS]\"]\n",
        "    for w in words:\n",
        "        sub = tokenizer.tokenize(w) or [tokenizer.unk_token]\n",
        "        first_idx.append(len(toks))\n",
        "        toks.extend(sub)\n",
        "    toks.append(\"[SEP]\")\n",
        "    ids = tokenizer.convert_tokens_to_ids(toks)\n",
        "    if len(ids) > max_len:\n",
        "        ids = ids[: max_len - 1] + [tokenizer.sep_token_id]\n",
        "        first_idx = [i for i in first_idx if i < len(ids)]\n",
        "        words = words[: len(first_idx)]\n",
        "    mask = [1] * len(ids)\n",
        "    inp = torch.tensor([ids], dtype=torch.long).to(device)\n",
        "    mask_t = torch.tensor([mask], dtype=torch.long).to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(inp, mask_t)\n",
        "    pred_tags = [id2label.get(preds[0][i], \"O\") for i in first_idx]\n",
        "    entities = {}\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        tag = pred_tags[i] if i < len(pred_tags) else \"O\"\n",
        "        if tag.startswith(\"B-\"):\n",
        "            entity_type = tag[2:]\n",
        "            phrase = [words[i]]\n",
        "            i += 1\n",
        "            while i < len(words) and i < len(pred_tags) and pred_tags[i] == f\"I-{entity_type}\":\n",
        "                phrase.append(words[i])\n",
        "                i += 1\n",
        "            entities.setdefault(entity_type, []).append(\" \".join(phrase))\n",
        "        else:\n",
        "            i += 1\n",
        "    return words, pred_tags, entities\n",
        "\n",
        "EMAIL_RE = re.compile(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}\", re.IGNORECASE)\n",
        "def extract_email_rules(text):\n",
        "    return list(dict.fromkeys(EMAIL_RE.findall(text)))\n",
        "\n",
        "def extract_name_heuristic(text):\n",
        "    lines = [ln.strip() for ln in text.strip().split(\"\\n\") if ln.strip()]\n",
        "    for line in lines[:4]:\n",
        "        if \"@\" in line or \"http\" in line.lower() or \"www.\" in line.lower():\n",
        "            continue\n",
        "        parts = line.split()\n",
        "        if 1 <= len(parts) <= 4 and all(p[0].isupper() for p in parts if len(p) > 0 and p[0].isalpha()):\n",
        "            c = \" \".join(parts)\n",
        "            if len(c) < 80 and not c.endswith(\".\"):\n",
        "                return [c]\n",
        "    return []\n",
        "\n",
        "def parse_resume_hybrid(text, tokenizer, model, device, id2label, max_len=512):\n",
        "    \"\"\"Hybrid: NAME/EMAIL from rules (high recall), SKILL/EXPERIENCE/EDUCATION/OCCUPATION from model.\"\"\"\n",
        "    text = text.strip()\n",
        "    rn, re_ = extract_name_heuristic(text), extract_email_rules(text)\n",
        "    words, pred_tags, entities = parse_resume(text, tokenizer, model, device, id2label, max_len)\n",
        "    if rn:\n",
        "        entities[\"NAME\"] = rn\n",
        "    if re_:\n",
        "        entities[\"EMAIL\"] = re_\n",
        "    return words, pred_tags, entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RESUME_TEXT = \"\"\"\n",
        "John Doe\n",
        "john.doe@email.com\n",
        "Software Engineer with 5 years of experience.\n",
        "Skills: Python, Java, Machine Learning.\n",
        "Education: BSc Computer Science, University of Colombo 2020.\n",
        "Worked at Tech Corp and Data Inc.\n",
        "\"\"\"\n",
        "words, tags, entities = parse_resume_hybrid(RESUME_TEXT.strip(), tokenizer, model, device, ID2LABEL)\n",
        "print(\"Entities (hybrid):\")\n",
        "for k, v in entities.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(\"\\nWord-level tags (first 30):\", list(zip(words[:30], tags[:30])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example texts â€“ check extracted values\n",
        "\n",
        "Run the cell below with different resume snippets to see extracted entities (NAME, EMAIL, SKILL, OCCUPATION, EDUCATION, EXPERIENCE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EXAMPLE_TEXTS = [\n",
        "    \"\"\"Jane Smith\n",
        "    jane.smith@gmail.com\n",
        "    Data Scientist | 4 years experience\n",
        "    Skills: Python, SQL, TensorFlow, NLP.\n",
        "    MSc Data Science, University of Moratuwa 2019.\n",
        "    Previous: Analytics Ltd, BigData Inc.\"\"\",\n",
        "    \"\"\"Kamal Perera\n",
        "    kamal.p@company.lk\n",
        "    Senior Software Engineer with 8+ years. Java, Spring, AWS.\n",
        "    BSc Eng (Hons) Computer Science, University of Peradeniya 2014.\n",
        "    Worked at Virtusa and WSO2.\"\"\",\n",
        "    \"\"\"Maria Garcia\n",
        "    maria.garcia@outlook.com\n",
        "    Product Manager. Agile, Jira, user research.\n",
        "    MBA, Colombo Business School 2021. BA Economics 2016.\n",
        "    Experience: StartupXYZ, Tech Solutions Pvt Ltd.\"\"\"\n",
        "]\n",
        "\n",
        "for i, text in enumerate(EXAMPLE_TEXTS, 1):\n",
        "    words, tags, entities = parse_resume_hybrid(text.strip(), tokenizer, model, device, ID2LABEL)\n",
        "    print(f\"{'='*60}\\nExample {i}\\n{'='*60}\")\n",
        "    print(\"Extracted entities:\")\n",
        "    for k, v in entities.items():\n",
        "        print(f\"  {k}: {v}\")\n",
        "    print(\"\\nWord-level tags (first 20):\", list(zip(words[:20], tags[:20])))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Evaluation (validation and test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validation evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report, f1_score\n",
        "\n",
        "model.eval()\n",
        "true_all, pred_all = [], []\n",
        "with torch.no_grad():\n",
        "    for inp, mask, labels in val_loader:\n",
        "        inp, mask = inp.to(device), mask.to(device)\n",
        "        preds = model(inp, mask)\n",
        "        for b in range(inp.size(0)):\n",
        "            m, labs = mask[b].cpu(), labels[b].cpu()\n",
        "            pred_b = preds[b]\n",
        "            tlist, plist = [], []\n",
        "            pos = 0\n",
        "            for i in range(m.size(0)):\n",
        "                if m[i].item() == 0:\n",
        "                    break\n",
        "                p = ID2LABEL[pred_b[pos]] if pos < len(pred_b) and pred_b[pos] < NUM_LABELS else \"O\"\n",
        "                pos += 1\n",
        "                if labs[i].item() == -100:\n",
        "                    continue\n",
        "                tlist.append(ID2LABEL[labs[i].item()])\n",
        "                plist.append(p)\n",
        "            if tlist and plist:\n",
        "                true_all.append(tlist)\n",
        "                pred_all.append(plist)\n",
        "\n",
        "print(classification_report(true_all, pred_all, zero_division=0))\n",
        "val_f1 = f1_score(true_all, pred_all, zero_division=0)\n",
        "print(\"Val F1 (entity-level):\", val_f1)\n",
        "total_tok = sum(len(t) for t in true_all)\n",
        "correct_tok = sum(sum(1 for a, b in zip(t, p) if a == b) for t, p in zip(true_all, pred_all))\n",
        "token_acc = correct_tok / total_tok if total_tok else 0.0\n",
        "print(\"Token accuracy: {:.2%}\".format(token_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test set evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ds = BertNERDataset(test_sents, test_labels, tokenizer)\n",
        "test_loader = DataLoader(test_ds, batch_size=8, collate_fn=collate)\n",
        "\n",
        "model.eval()\n",
        "true_test, pred_test = [], []\n",
        "with torch.no_grad():\n",
        "    for inp, mask, labels in test_loader:\n",
        "        inp, mask = inp.to(device), mask.to(device)\n",
        "        preds = model(inp, mask)\n",
        "        for b in range(inp.size(0)):\n",
        "            m, labs = mask[b].cpu(), labels[b].cpu()\n",
        "            pred_b = preds[b]\n",
        "            tlist, plist = [], []\n",
        "            pos = 0\n",
        "            for i in range(m.size(0)):\n",
        "                if m[i].item() == 0:\n",
        "                    break\n",
        "                p = ID2LABEL[pred_b[pos]] if pos < len(pred_b) and pred_b[pos] < NUM_LABELS else \"O\"\n",
        "                pos += 1\n",
        "                if labs[i].item() == -100:\n",
        "                    continue\n",
        "                tlist.append(ID2LABEL[labs[i].item()])\n",
        "                plist.append(p)\n",
        "            if tlist and plist:\n",
        "                true_test.append(tlist)\n",
        "                pred_test.append(plist)\n",
        "\n",
        "print(\"--- Test set results ---\")\n",
        "print(classification_report(true_test, pred_test, zero_division=0))\n",
        "print(\"Test F1:\", f1_score(true_test, pred_test, zero_division=0))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
